{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##import all the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "from gensim.models import word2vec\n",
    "import sklearn\n",
    "from sklearn import manifold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from gensim import similarities\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ingre = pd.read_csv('recipe_dataset/recipe_ingre.csv')\n",
    "#df = df_ingre.drop_duplicates(subset = ['RECIPE_ID', 'IRDNT_NM'])\n",
    "#df.to_csv('recipe_dataset/recipe_ingre2.csv', encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ingre = pd.read_csv('recipe_dataset/db/recipe_ingre.csv')\n",
    "df_basic = pd.read_csv('recipe_dataset/db/recipe_basic.csv', encoding=\"cp949\")\n",
    "\n",
    "df_tmp=df_ingre[['RECIPE_ID','IRDNT_NM']]\n",
    "df_tmp_arr=[[]for i in range(538)]\n",
    "num=0\n",
    "for i in df_tmp['IRDNT_NM'] :\n",
    "    df_tmp_arr[df_tmp['RECIPE_ID'][num]].append(i)\n",
    "    num+=1\n",
    "    \n",
    "df_tmp_arr.pop(0)\n",
    "num=0\n",
    "for i in df_tmp_arr :\n",
    "    df_tmp_arr[num] = list(set(df_tmp_arr[num]))\n",
    "    num+=1\n",
    "    \n",
    "ingre_dict = {}\n",
    "\n",
    "for i in range(1, 538, 1):\n",
    "    ingre_dict[str(i)] = df_tmp_arr[i-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bags_of_words = [ Counter(IRDNT_NM) for IRDNT_NM in df_tmp_arr ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "537"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bags_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find sum of every ingredient using Counter()\n",
    "sumbags = sum(bags_of_words, Counter())\n",
    "\n",
    "\n",
    "# Finally, plot the 10 most used ingredients\n",
    "clean_df = pd.DataFrame.from_dict(sumbags, orient='index').reset_index()\n",
    "clean_df = clean_df.rename(columns={'index':'IRDNT_NM', 0:'count'})\n",
    "\n",
    "top_ing = clean_df.sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingr_only_dict = clean_df['IRDNT_NM'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all clean ingredients in list format per recipe\n",
    "ingr_list = []\n",
    "for IRDNT_NM in df_tmp_arr:\n",
    "    ingr_list.append(IRDNT_NM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "537"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ingr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Get clean ingredients to be used as an input for word2vec model to identify ingredient similarity.\n",
    "\n",
    "ingr_clean_df = pd.DataFrame({'IRDNT_NM':ingr_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-b6b1f6b01e9a>:10: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  model.init_sims(replace=True)\n"
     ]
    }
   ],
   "source": [
    "num_features = 300   # Word vector dimensionality                      \n",
    "context = 1        # Context window size; \n",
    "downsampling = 1e-3   # threshold for configuring which higher-frequency words are randomly downsampled\n",
    "\n",
    "# Initialize and train the model \n",
    "model = word2vec.Word2Vec(ingr_list, vector_size=num_features, window = context, sample = downsampling)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_list = []\n",
    "for sublist in ingr_list:\n",
    "    for item in sublist:\n",
    "        if item not in flatten_list:\n",
    "            flatten_list.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_sim_list = []\n",
    "corpus_sim_dict = {}\n",
    "input_list = []\n",
    "for i in flatten_list:\n",
    "    try: \n",
    "        if len(i) > 0:\n",
    "            #print i\n",
    "            corpus_sim_dict.update({i:model.wv.most_similar(i)})      \n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df = pd.DataFrame([])\n",
    "for key,value in corpus_sim_dict.items():\n",
    "    for i in value:\n",
    "        sim_df = sim_df.append(pd.DataFrame({'Similar Ingredient':i[0],'Word2Vec Value': i[1],'Ingredient': key }, index=[0]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vecTSNE = word2vec.Word2Vec(\n",
    "    sg=1,\n",
    "    vector_size=num_features, window = context, sample = downsampling,\n",
    "    min_count=3\n",
    ")\n",
    "word2vecTSNE.build_vocab(ingr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2381128, 5562000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vecTSNE.train(ingr_list, total_examples= word2vecTSNE.corpus_count, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"trained\"):\n",
    "    os.makedirs(\"trained\")\n",
    "word2vecTSNE.save(os.path.join(\"trained\", \"word2vecTSNE.w2v\"))\n",
    "word2vecTSNE = word2vec.Word2Vec.load(os.path.join(\"trained\", \"word2vecTSNE.w2v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = sklearn.manifold.TSNE(n_components=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_word_vectors_matrix = word2vecTSNE.wv.vectors\n",
    "all_word_vectors_matrix_2d = tsne.fit_transform(all_word_vectors_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df.to_csv('word2vec_ingredient_similarity.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('word2vec_ingredient_similarity.csv')\n",
    "df = df.sort_values('Word2Vec Value',ascending=False)\n",
    "top_df = df.groupby('Ingredient').head(5)\n",
    "top_df.to_csv('word2vec_ingredient_similarity_top.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary for all the ingredients in the recipe list\n",
    "\n",
    "dictionary = corpora.Dictionary(ingr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying doc2bow on the dictionary of ingredients, which converts the ingredient to a number in every recipe\n",
    "#This input format is needed for TfIdfmodel\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in ingr_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "tfidf = models.TfidfModel(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use similarities library from gensim to get the cosine similarity of the tfidf results\n",
    "\n",
    "index = similarities.MatrixSimilarity(tfidf[bow_corpus])\n",
    "index.save('ingr.index')\n",
    "index = similarities.MatrixSimilarity.load('ingr.index')\n",
    "\n",
    "sims = index[corpus_tfidf]\n",
    "sims_list = [(i,j) for i,j in enumerate(sims)]\n",
    "\n",
    "#Creating a list to hold the cosine similarity results for tfidf\n",
    "tf_idf_list = []\n",
    "\n",
    "for i,j in enumerate(sims_list):\n",
    "    tf_idf_list.append(sims_list[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create recipe dict- to be used in creating dataframe in next step - used to decode recipe id\n",
    "recipe_dict = {k: v for k, v in enumerate(df_basic.RECIPE_NM_KO)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use cosine similarity results to get the top 10 similar recipes for every recipe.\n",
    "tf_idf_top  = []\n",
    "similar_recipes_df = pd.DataFrame([])\n",
    "same_item = []\n",
    "\n",
    "#Get only top 11 largest values from the tf_idf_list - 1 recipe will be the same as itself (hence 12)\n",
    "for i,item in enumerate(tf_idf_list):\n",
    "    tf_idf_top.append(heapq.nlargest(11,enumerate(item), key=lambda x: x[1]))\n",
    "\n",
    "#Remove the recipe value with 1.0 similarity - since it is the same recipe\n",
    "for i,list_item in enumerate(tf_idf_top):\n",
    "    for j,k in enumerate(list_item):\n",
    "        if tf_idf_top[i][j][1] != 1.0:\n",
    "            similar_recipes_df = similar_recipes_df.append(pd.DataFrame({'Similar_Recipe_ID': recipe_dict.get(tf_idf_top[i][j][0]),'TF-IDF Value': tf_idf_top[i][j][1],'Recipe_ID': recipe_dict.get(i)}, index=[0]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_recipes_df.to_csv('similar_recipes_top_10_tf_idf.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_recipes_df = pd.read_csv('similar_recipes_top_10_tf_idf.csv')\n",
    "similar_recipes_df = similar_recipes_df[similar_recipes_df['Recipe_ID'] != similar_recipes_df['Similar_Recipe_ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Similar_Recipe_ID</th>\n",
       "      <th>TF-IDF Value</th>\n",
       "      <th>Recipe_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>사색나물</td>\n",
       "      <td>0.438845</td>\n",
       "      <td>나물비빔밥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>돌솥비빔밥</td>\n",
       "      <td>0.406001</td>\n",
       "      <td>나물비빔밥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>상추겉절이비빔밥</td>\n",
       "      <td>0.394248</td>\n",
       "      <td>나물비빔밥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>콩나물잡채</td>\n",
       "      <td>0.379962</td>\n",
       "      <td>나물비빔밥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>묵과양념장</td>\n",
       "      <td>0.376855</td>\n",
       "      <td>나물비빔밥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5470</th>\n",
       "      <td>5470</td>\n",
       "      <td>잡채밥</td>\n",
       "      <td>0.203561</td>\n",
       "      <td>콩비지동그랑땡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5471</th>\n",
       "      <td>5471</td>\n",
       "      <td>배추속댓국</td>\n",
       "      <td>0.201293</td>\n",
       "      <td>콩비지동그랑땡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5472</th>\n",
       "      <td>5472</td>\n",
       "      <td>중식식볶음밥</td>\n",
       "      <td>0.184931</td>\n",
       "      <td>콩비지동그랑땡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5473</th>\n",
       "      <td>5473</td>\n",
       "      <td>제육배추찜</td>\n",
       "      <td>0.184076</td>\n",
       "      <td>콩비지동그랑땡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5474</th>\n",
       "      <td>5474</td>\n",
       "      <td>꽃만두국(완당국)</td>\n",
       "      <td>0.182063</td>\n",
       "      <td>콩비지동그랑땡</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5370 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 Similar_Recipe_ID  TF-IDF Value Recipe_ID\n",
       "1              1              사색나물      0.438845     나물비빔밥\n",
       "2              2             돌솥비빔밥      0.406001     나물비빔밥\n",
       "3              3          상추겉절이비빔밥      0.394248     나물비빔밥\n",
       "4              4             콩나물잡채      0.379962     나물비빔밥\n",
       "5              5             묵과양념장      0.376855     나물비빔밥\n",
       "...          ...               ...           ...       ...\n",
       "5470        5470               잡채밥      0.203561   콩비지동그랑땡\n",
       "5471        5471             배추속댓국      0.201293   콩비지동그랑땡\n",
       "5472        5472            중식식볶음밥      0.184931   콩비지동그랑땡\n",
       "5473        5473             제육배추찜      0.184076   콩비지동그랑땡\n",
       "5474        5474         꽃만두국(완당국)      0.182063   콩비지동그랑땡\n",
       "\n",
       "[5370 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_recipes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "similar_recipes_df = similar_recipes_df[similar_recipes_df['Recipe_ID'] != similar_recipes_df['Similar_Recipe_ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create cosine similarity matrix for all recipes 27637*27637\n",
    "#Since this is a huge matrix, the top 10 similar recipe logic is a better option.\n",
    "\n",
    "names = [i for i in range(1,len(tf_idf_list))]\n",
    "final_df = pd.DataFrame.from_dict(zip(names,tf_idf_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_basic['RECIPE_ID'] = df_basic.index+1\n",
    "recipe_name_df = df_basic[['RECIPE_ID','RECIPE_NM_KO']]\n",
    "final_df['RECIPE_ID'] = final_df.index+1\n",
    "\n",
    "recipe_tf_idf_df = final_df.merge(recipe_name_df,how='left', left_on='RECIPE_ID', right_on='RECIPE_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list from tfidf results\n",
    "#This will be used to identify ingredient importance within every recipe\n",
    "\n",
    "corpus_list = []\n",
    "for doc in corpus_tfidf:\n",
    "    corpus_list.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a flat list to eliminate repetition of ingredients and create a dict to hold the results\n",
    "\n",
    "flat_list = []\n",
    "for sublist in ingr_list:\n",
    "    for item in sublist:\n",
    "        if item not in flat_list:\n",
    "            flat_list.append(item)\n",
    "ing_dict =  {k: v for k, v in enumerate(flat_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe with tf-idf values per ingredient for every recipe.\n",
    "corpus_df = pd.DataFrame([])\n",
    "\n",
    "for i,list_item in enumerate(corpus_list):\n",
    "    for j,k in enumerate(list_item):\n",
    "        corpus_df = corpus_df.append(pd.DataFrame({'IRDNT_NM': dictionary.get(corpus_list[i][j][0]),'TF-IDF Value': corpus_list[i][j][1],'Recipe_ID': i}, index=[0]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_basic['RECIPE_ID'] = df_basic.index\n",
    "recipe_tf_idf_df = corpus_df.merge(df_basic,how='left', left_on='Recipe_ID', right_on='RECIPE_ID')\n",
    "recipe_tf_idf_df = recipe_tf_idf_df[['Recipe_ID','RECIPE_NM_KO','IRDNT_NM','TF-IDF Value']]\n",
    "tf_idf_sorting = recipe_tf_idf_df.sort_values(by=['Recipe_ID', 'IRDNT_NM'], axis=0)\n",
    "tf_idf_sorting.set_index('Recipe_ID', inplace=True)\n",
    "tf_idf_sorting.index = tf_idf_sorting.index+1\n",
    "tf_idf_sorting.reset_index(inplace=True)\n",
    "tf_idf_sorting.to_csv('recipe_dataset/tf_idf_sorting.csv', encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recipe_ID</th>\n",
       "      <th>RECIPE_NM_KO</th>\n",
       "      <th>IRDNT_NM</th>\n",
       "      <th>TF-IDF_WEIGHT</th>\n",
       "      <th>TF-IDF Value</th>\n",
       "      <th>SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>나물비빔밥</td>\n",
       "      <td>간장</td>\n",
       "      <td>0.203117</td>\n",
       "      <td>0.067706</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>나물비빔밥</td>\n",
       "      <td>계란</td>\n",
       "      <td>0.156383</td>\n",
       "      <td>0.156383</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>나물비빔밥</td>\n",
       "      <td>고사리</td>\n",
       "      <td>1.801023</td>\n",
       "      <td>0.360205</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>나물비빔밥</td>\n",
       "      <td>고추장</td>\n",
       "      <td>0.542290</td>\n",
       "      <td>0.180763</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>나물비빔밥</td>\n",
       "      <td>다진마늘</td>\n",
       "      <td>0.171398</td>\n",
       "      <td>0.085699</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5557</th>\n",
       "      <td>537</td>\n",
       "      <td>콩비지동그랑땡</td>\n",
       "      <td>전분</td>\n",
       "      <td>1.687980</td>\n",
       "      <td>0.421995</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5558</th>\n",
       "      <td>537</td>\n",
       "      <td>콩비지동그랑땡</td>\n",
       "      <td>참기름</td>\n",
       "      <td>0.170131</td>\n",
       "      <td>0.085066</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5559</th>\n",
       "      <td>537</td>\n",
       "      <td>콩비지동그랑땡</td>\n",
       "      <td>콩비지</td>\n",
       "      <td>2.706960</td>\n",
       "      <td>0.541392</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5560</th>\n",
       "      <td>537</td>\n",
       "      <td>콩비지동그랑땡</td>\n",
       "      <td>호박</td>\n",
       "      <td>0.283380</td>\n",
       "      <td>0.283380</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5561</th>\n",
       "      <td>537</td>\n",
       "      <td>콩비지동그랑땡</td>\n",
       "      <td>후춧가루</td>\n",
       "      <td>0.161727</td>\n",
       "      <td>0.080864</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5562 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Recipe_ID RECIPE_NM_KO IRDNT_NM  TF-IDF_WEIGHT  TF-IDF Value  SCORE\n",
       "0             1        나물비빔밥       간장       0.203117      0.067706      3\n",
       "1             1        나물비빔밥       계란       0.156383      0.156383      1\n",
       "2             1        나물비빔밥      고사리       1.801023      0.360205      5\n",
       "3             1        나물비빔밥      고추장       0.542290      0.180763      3\n",
       "4             1        나물비빔밥     다진마늘       0.171398      0.085699      2\n",
       "...         ...          ...      ...            ...           ...    ...\n",
       "5557        537      콩비지동그랑땡       전분       1.687980      0.421995      4\n",
       "5558        537      콩비지동그랑땡      참기름       0.170131      0.085066      2\n",
       "5559        537      콩비지동그랑땡      콩비지       2.706960      0.541392      5\n",
       "5560        537      콩비지동그랑땡       호박       0.283380      0.283380      1\n",
       "5561        537      콩비지동그랑땡     후춧가루       0.161727      0.080864      2\n",
       "\n",
       "[5562 rows x 6 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_df = pd.read_csv('recipe_dataset/tf_idf_sorting.csv')\n",
    "tf_idf_df = tf_idf_df.drop(['Unnamed: 0'], axis = 1)\n",
    "tf_idf_df = pd.concat([tf_idf_df, df_ingre[\"SCORE\"]], axis = 1)\n",
    "tfidf_weight = pd.DataFrame(tf_idf_df['TF-IDF Value'].mul(tf_idf_df['SCORE'], axis=0, level=None, fill_value=None))\n",
    "tf_idf_df.insert(3, 'TF-IDF_WEIGHT',tfidf_weight)\n",
    "tf_idf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'tf_idf_df.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-344607e3ef49>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf_idf_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tf_idf_df.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8-sig\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\User\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors)\u001b[0m\n\u001b[0;32m   3168\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3169\u001b[0m         )\n\u001b[1;32m-> 3170\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3172\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\User\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m             f, handles = get_handle(\n\u001b[0m\u001b[0;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\User\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[0;32m    491\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[1;31m# No explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'tf_idf_df.csv'"
     ]
    }
   ],
   "source": [
    "tf_idf_df.to_csv('tf_idf_df.csv', encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-e22ac14f210e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratings_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1234\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(ratings_df, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
